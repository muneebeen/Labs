{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XBX4Js-iLcT"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzSjupC-rlzm"
   },
   "source": [
    "# Objective of the task is to predict the Profit of the state based on the other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UJgt7Pe4hBL9"
   },
   "outputs": [],
   "source": [
    "# Your code to import numpy\n",
    "# Your code to import panda\n",
    "# Your code to import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-PDHsuSxicT-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to read file\n",
    "# Your code to print sample data\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27F819fqr0MK"
   },
   "source": [
    "# Separate the independednt and Dependent variables.\n",
    "# Profit is the dependedent variable\n",
    "\n",
    "## What is the role of the axis and inplace in following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "LUXxD-gViltR"
   },
   "outputs": [],
   "source": [
    "y = np.asarray(dataset['Profit'].values.tolist())\n",
    "\n",
    "dataset.drop([\"Profit\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8d-0FfnsN0O"
   },
   "source": [
    "# We will convert  Categorical Variable values \"State\" to numbers with the One Hot Encoding Technique\n",
    "\n",
    "# Initially, we will counts value that the feature \"State\" can take.\n",
    "\n",
    "# Remember .value_counts() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "M3CB3Ct9i4an"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New York      17\n",
       "California    17\n",
       "Florida       16\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:,3].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WSSeKczss1U"
   },
   "source": [
    "# Replacing the three states by the numbers 1, 2, 3.\n",
    "# This is also called as the LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "RonZ0XJVi7VO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend  State\n",
       "0   165349.20       136897.80        471784.10      2\n",
       "1   162597.70       151377.59        443898.53      1\n",
       "2   153441.51       101145.55        407934.54      3\n",
       "3   144372.41       118671.85        383199.62      2\n",
       "4   142107.34        91391.77        366168.42      3\n",
       "5   131876.90        99814.71        362861.36      2\n",
       "6   134615.46       147198.87        127716.82      1\n",
       "7   130298.13       145530.06        323876.68      3\n",
       "8   120542.52       148718.95        311613.29      2\n",
       "9   123334.88       108679.17        304981.62      1\n",
       "10  101913.08       110594.11        229160.95      3\n",
       "11  100671.96        91790.61        249744.55      1\n",
       "12   93863.75       127320.38        249839.44      3\n",
       "13   91992.39       135495.07        252664.93      1\n",
       "14  119943.24       156547.42        256512.92      3\n",
       "15  114523.61       122616.84        261776.23      2\n",
       "16   78013.11       121597.55        264346.06      1\n",
       "17   94657.16       145077.58        282574.31      2\n",
       "18   91749.16       114175.79        294919.57      3\n",
       "19   86419.70       153514.11             0.00      2\n",
       "20   76253.86       113867.30        298664.47      1\n",
       "21   78389.47       153773.43        299737.29      2\n",
       "22   73994.56       122782.75        303319.26      3\n",
       "23   67532.53       105751.03        304768.73      3\n",
       "24   77044.01        99281.34        140574.81      2\n",
       "25   64664.71       139553.16        137962.62      1\n",
       "26   75328.87       144135.98        134050.07      3\n",
       "27   72107.60       127864.55        353183.81      2\n",
       "28   66051.52       182645.56        118148.20      3\n",
       "29   65605.48       153032.06        107138.38      2\n",
       "30   61994.48       115641.28         91131.24      3\n",
       "31   61136.38       152701.92         88218.23      2\n",
       "32   63408.86       129219.61         46085.25      1\n",
       "33   55493.95       103057.49        214634.81      3\n",
       "34   46426.07       157693.92        210797.67      1\n",
       "35   46014.02        85047.44        205517.64      2\n",
       "36   28663.76       127056.21        201126.82      3\n",
       "37   44069.95        51283.14        197029.42      1\n",
       "38   20229.59        65947.93        185265.10      2\n",
       "39   38558.51        82982.09        174999.30      1\n",
       "40   28754.33       118546.05        172795.67      1\n",
       "41   27892.92        84710.77        164470.71      3\n",
       "42   23640.93        96189.63        148001.11      1\n",
       "43   15505.73       127382.30         35534.17      2\n",
       "44   22177.74       154806.14         28334.72      1\n",
       "45    1000.23       124153.04          1903.93      2\n",
       "46    1315.46       115816.21        297114.46      3\n",
       "47       0.00       135426.92             0.00      1\n",
       "48     542.05        51743.15             0.00      2\n",
       "49       0.00       116983.80         45173.06      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.replace(to_replace=[\"California\",\"New York\", \"Florida\"], value=[1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQungUWgtBIL"
   },
   "source": [
    "# We will create 3 more columns for the three states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "sEz2FMUfi9gK"
   },
   "outputs": [],
   "source": [
    "dataset[\"California\"] = dataset.iloc[:, 3]\n",
    "dataset[\"New York\"] = dataset.iloc[:,3]\n",
    "dataset[\"Florida\"] = dataset.iloc[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unUvog8WtNpu"
   },
   "source": [
    "# Check how the dataset looks now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "98teOtjzjIp2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>California</th>\n",
       "      <th>New York</th>\n",
       "      <th>Florida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State  California  \\\n",
       "0  165349.20       136897.80        471784.10    New York    New York   \n",
       "1  162597.70       151377.59        443898.53  California  California   \n",
       "2  153441.51       101145.55        407934.54     Florida     Florida   \n",
       "3  144372.41       118671.85        383199.62    New York    New York   \n",
       "4  142107.34        91391.77        366168.42     Florida     Florida   \n",
       "\n",
       "     New York     Florida  \n",
       "0    New York    New York  \n",
       "1  California  California  \n",
       "2     Florida     Florida  \n",
       "3    New York    New York  \n",
       "4     Florida     Florida  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print few samples of dataset.\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoLuUTSBtVZj"
   },
   "source": [
    "# Performing one hot encoding for the column Calfornia.\n",
    "## Replace text 'California' with 1 and others with 0 for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ZABX9aatjLdw"
   },
   "outputs": [],
   "source": [
    "dataset.loc[dataset[\"California\"]!=\"California\", \"California\"] = 0\n",
    "dataset.loc[dataset[\"California\"]==\"California\", \"California\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rrqbptyntrgw"
   },
   "source": [
    "# Perform the one hot encoding for New York and the Florida column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "6zcJTPVxjPYk"
   },
   "outputs": [],
   "source": [
    "# Your code to perform one hot encoding for New York column.\n",
    "dataset.loc[dataset[\"New York\"]!=\"New York\", \"New York\"] = 0\n",
    "dataset.loc[dataset[\"New York\"]==\"New York\", \"New York\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "XnoCxjbejSmN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code to perform one hot encoding for Florida column.\n",
    "dataset.loc[dataset[\"Florida\"]!=\"Florida\", \"Florida\"] = 0\n",
    "dataset.loc[dataset[\"Florida\"]==\"Florida\", \"Florida\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of9U6eX4uGwj"
   },
   "source": [
    "# Now look at the dataset\n",
    "## Can you find the state name from numbers in last three columns only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4JUs_zpLjV_e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New York', 'California', 'Florida', 'New York', 'Florida', 'New York', 'California', 'Florida', 'New York', 'California', 'Florida', 'California', 'Florida', 'California', 'Florida', 'New York', 'California', 'New York', 'Florida', 'New York', 'California', 'New York', 'Florida', 'Florida', 'New York', 'California', 'Florida', 'New York', 'Florida', 'New York', 'Florida', 'New York', 'California', 'Florida', 'California', 'New York', 'Florida', 'California', 'New York', 'California', 'California', 'Florida', 'California', 'New York', 'California', 'New York', 'Florida', 'California', 'New York', 'California']\n"
     ]
    }
   ],
   "source": [
    "state_columns = ['California', 'New York', 'Florida']\n",
    "dataset[state_columns] = dataset[state_columns].astype(int)\n",
    "state_names = dataset[state_columns].idxmax(axis=1).tolist()\n",
    "print(state_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dm80EXTuX8w"
   },
   "source": [
    "# Drop the State and one of the three states column.\n",
    "## Question - Why we are dropping one column for the state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "hAFgpUrmjZbp"
   },
   "outputs": [],
   "source": [
    "# Your code to drop State and Florida column\n",
    "dataset.drop(['State'], axis = 1, inplace = True)\n",
    "dataset.drop(['Florida'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4kE329ku90q"
   },
   "source": [
    "# Lets's check the dataset again.\n",
    "## Question - Can you guess the name of three states from the numbers (1/0) in last two column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "9JtxL7LPj-Ze"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R&D Spend  Administration  Marketing Spend  California  New York\n",
      "0   165349.20       136897.80        471784.10           0         1\n",
      "1   162597.70       151377.59        443898.53           1         0\n",
      "2   153441.51       101145.55        407934.54           0         0\n",
      "3   144372.41       118671.85        383199.62           0         1\n",
      "4   142107.34        91391.77        366168.42           0         0\n",
      "5   131876.90        99814.71        362861.36           0         1\n",
      "6   134615.46       147198.87        127716.82           1         0\n",
      "7   130298.13       145530.06        323876.68           0         0\n",
      "8   120542.52       148718.95        311613.29           0         1\n",
      "9   123334.88       108679.17        304981.62           1         0\n",
      "10  101913.08       110594.11        229160.95           0         0\n",
      "11  100671.96        91790.61        249744.55           1         0\n",
      "12   93863.75       127320.38        249839.44           0         0\n",
      "13   91992.39       135495.07        252664.93           1         0\n",
      "14  119943.24       156547.42        256512.92           0         0\n",
      "15  114523.61       122616.84        261776.23           0         1\n",
      "16   78013.11       121597.55        264346.06           1         0\n",
      "17   94657.16       145077.58        282574.31           0         1\n",
      "18   91749.16       114175.79        294919.57           0         0\n",
      "19   86419.70       153514.11             0.00           0         1\n",
      "20   76253.86       113867.30        298664.47           1         0\n",
      "21   78389.47       153773.43        299737.29           0         1\n",
      "22   73994.56       122782.75        303319.26           0         0\n",
      "23   67532.53       105751.03        304768.73           0         0\n",
      "24   77044.01        99281.34        140574.81           0         1\n",
      "25   64664.71       139553.16        137962.62           1         0\n",
      "26   75328.87       144135.98        134050.07           0         0\n",
      "27   72107.60       127864.55        353183.81           0         1\n",
      "28   66051.52       182645.56        118148.20           0         0\n",
      "29   65605.48       153032.06        107138.38           0         1\n",
      "30   61994.48       115641.28         91131.24           0         0\n",
      "31   61136.38       152701.92         88218.23           0         1\n",
      "32   63408.86       129219.61         46085.25           1         0\n",
      "33   55493.95       103057.49        214634.81           0         0\n",
      "34   46426.07       157693.92        210797.67           1         0\n",
      "35   46014.02        85047.44        205517.64           0         1\n",
      "36   28663.76       127056.21        201126.82           0         0\n",
      "37   44069.95        51283.14        197029.42           1         0\n",
      "38   20229.59        65947.93        185265.10           0         1\n",
      "39   38558.51        82982.09        174999.30           1         0\n",
      "40   28754.33       118546.05        172795.67           1         0\n",
      "41   27892.92        84710.77        164470.71           0         0\n",
      "42   23640.93        96189.63        148001.11           1         0\n",
      "43   15505.73       127382.30         35534.17           0         1\n",
      "44   22177.74       154806.14         28334.72           1         0\n",
      "45    1000.23       124153.04          1903.93           0         1\n",
      "46    1315.46       115816.21        297114.46           0         0\n",
      "47       0.00       135426.92             0.00           1         0\n",
      "48     542.05        51743.15             0.00           0         1\n",
      "49       0.00       116983.80         45173.06           1         0\n",
      "['New York', 'California', 'California', 'New York', 'California', 'New York', 'California', 'California', 'New York', 'California', 'California', 'California', 'California', 'California', 'California', 'New York', 'California', 'New York', 'California', 'New York', 'California', 'New York', 'California', 'California', 'New York', 'California', 'California', 'New York', 'California', 'New York', 'California', 'New York', 'California', 'California', 'California', 'New York', 'California', 'California', 'New York', 'California', 'California', 'California', 'California', 'New York', 'California', 'New York', 'California', 'California', 'New York', 'California']\n"
     ]
    }
   ],
   "source": [
    "# Your code to print sample dataset.\n",
    "print(dataset)\n",
    "state_columns = ['California', 'New York']\n",
    "dataset[state_columns] = dataset[state_columns].astype(int)\n",
    "state_names = dataset[state_columns].idxmax(axis=1).tolist()\n",
    "print(state_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIQepd2JvPmH"
   },
   "source": [
    "# Let's further process independent variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "KuLd1d0ukA_E"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.asarray(dataset.values.tolist()).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jbjZBzrwPWM"
   },
   "source": [
    "# Print the shapes of the aray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "NWMcIEalkHJp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 5)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# Your code to print the shape of X\n",
    "# Your code to print the shape of y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mkuT1JvwXQS"
   },
   "source": [
    "# Change the shape of the dependent variable to (len(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "kkOIedKLkJsS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "# Your code to change the shape of the y to (len(y), 1)\n",
    "y = y.reshape(len(y), 1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "086Arswgwifr"
   },
   "source": [
    "# Perform feature scaling\n",
    "## We will study this in detail in class.\n",
    "## For now, guess what following code is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "3xY_jX90kqWe"
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(X.shape[1]-2):\n",
    "    X[:,i] = (X[:,i] - int(np.mean(X[:,i])))/np.std(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "d5X_d-T-k2_f"
   },
   "outputs": [],
   "source": [
    "y = (y - int(np.mean(y)))/np.std(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDibPJ8Xw6qJ"
   },
   "source": [
    "### Adding the feature X0 = 1, so we have the equation: y =  theta[0] * X0 + theta[1] * X1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "6IJwREnmk53K"
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X,np.ones((50,1))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xeqVGkmxNqW"
   },
   "source": [
    "# Let's see X, y and their shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "F72giE7Zk8Xc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Your code to print sample values in X\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "wiCADV4Xk-40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "# Your code to print the sample values in y\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTjU0Q-cxser"
   },
   "source": [
    "# Let's assign the X to a variable Independedent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "YdWZQ-b5lDJa"
   },
   "outputs": [],
   "source": [
    "Indpendent_Variables = pd.DataFrame(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gMeaKTBx4-d"
   },
   "source": [
    "# Print Independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "g4ZT1IjrlNHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2    3    4    5\n",
      "0   2.016425  0.560776  2.153944  0.0  1.0  1.0\n",
      "1   1.955874  1.082830  1.923601  1.0  0.0  1.0\n",
      "2   1.754377 -0.728234  1.626528  0.0  0.0  1.0\n",
      "3   1.554797 -0.096342  1.422211  0.0  1.0  1.0\n",
      "4   1.504951 -1.079896  1.281529  0.0  0.0  1.0\n",
      "5   1.279814 -0.776216  1.254211  0.0  1.0  1.0\n",
      "6   1.340080  0.932170 -0.688149  1.0  0.0  1.0\n",
      "7   1.245070  0.872003  0.932187  0.0  0.0  1.0\n",
      "8   1.030382  0.986975  0.830888  0.0  1.0  1.0\n",
      "9   1.091833 -0.456617  0.776108  1.0  0.0  1.0\n",
      "10  0.620412 -0.387576  0.149808  0.0  0.0  1.0\n",
      "11  0.593099 -1.065517  0.319834  1.0  0.0  1.0\n",
      "12  0.443273  0.215472  0.320618  0.0  0.0  1.0\n",
      "13  0.402091  0.510202  0.343958  1.0  0.0  1.0\n",
      "14  1.017194  1.269222  0.375743  0.0  0.0  1.0\n",
      "15  0.897927  0.045891  0.419220  0.0  1.0  1.0\n",
      "16  0.094455  0.009141  0.440447  1.0  0.0  1.0\n",
      "17  0.460734  0.855689  0.591018  0.0  1.0  1.0\n",
      "18  0.396738 -0.258442  0.692993  0.0  0.0  1.0\n",
      "19  0.279455  1.159860 -1.743126  0.0  1.0  1.0\n",
      "20  0.055740 -0.269565  0.723927  1.0  0.0  1.0\n",
      "21  0.102737  1.169209  0.732789  0.0  1.0  1.0\n",
      "22  0.006020  0.051873  0.762377  0.0  0.0  1.0\n",
      "23 -0.136187 -0.562188  0.774350  0.0  0.0  1.0\n",
      "24  0.073128 -0.795446 -0.581938  0.0  1.0  1.0\n",
      "25 -0.199298  0.656512 -0.603516  1.0  0.0  1.0\n",
      "26  0.035384  0.821741 -0.635835  0.0  0.0  1.0\n",
      "27 -0.035505  0.235092  1.174272  0.0  1.0  1.0\n",
      "28 -0.168779  2.210164 -0.767189  0.0  0.0  1.0\n",
      "29 -0.178595  1.142480 -0.858133  0.0  1.0  1.0\n",
      "30 -0.258061 -0.205606 -0.990356  0.0  0.0  1.0\n",
      "31 -0.276945  1.130577 -1.014419  0.0  1.0  1.0\n",
      "32 -0.226935  0.283947 -1.362449  1.0  0.0  1.0\n",
      "33 -0.401115 -0.659301  0.029818  0.0  0.0  1.0\n",
      "34 -0.600669  1.310558 -0.001878  1.0  0.0  1.0\n",
      "35 -0.609736 -1.308634 -0.045492  0.0  1.0  1.0\n",
      "36 -0.991557  0.205948 -0.081762  0.0  0.0  1.0\n",
      "37 -0.652519 -2.525971 -0.115607  1.0  0.0  1.0\n",
      "38 -1.177164 -1.997247 -0.212784  0.0  1.0  1.0\n",
      "39 -0.773807 -1.383099 -0.297582  1.0  0.0  1.0\n",
      "40 -0.989563 -0.100877 -0.315785  1.0  0.0  1.0\n",
      "41 -1.008520 -1.320773 -0.384552  0.0  0.0  1.0\n",
      "42 -1.102092 -0.906914 -0.520595  1.0  0.0  1.0\n",
      "43 -1.281120  0.217705 -1.449604  0.0  1.0  1.0\n",
      "44 -1.134292  1.206442 -1.509073  1.0  0.0  1.0\n",
      "45 -1.600337  0.101277 -1.727399  0.0  1.0  1.0\n",
      "46 -1.593400 -0.199299  0.711123  0.0  0.0  1.0\n",
      "47 -1.622348  0.507745 -1.743126  1.0  0.0  1.0\n",
      "48 -1.610420 -2.509386 -1.743126  0.0  1.0  1.0\n",
      "49 -1.622348 -0.157202 -1.369984  1.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# Your code to print independent variable.\n",
    "print(Indpendent_Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6id_qS-wx_PY"
   },
   "source": [
    "# Following function splits the data into two sets - trainset and testset.\n",
    "# We can also do the same operation using  train_test_split method available in sklearn.model_selection.\n",
    "# But, let's create our own method to split data.\n",
    "\n",
    "# In the following code, set radom_state as your SID.\n",
    "\n",
    "## Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "JyUnKqYklPXO"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size = 0.2, random_state = 2249148):  # Set variable random_state as your SID\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    data_test_size = int(X.shape[0] * test_size)\n",
    "\n",
    "    train_indices = indices[data_test_size:]\n",
    "    test_indices = indices[:data_test_size]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # Your code to return X_train, y_train, X_test, y_test\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SZXGbPozKhg"
   },
   "source": [
    "#Comment each line of the following code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "vIoOKmLMz7SG"
   },
   "outputs": [],
   "source": [
    "def forward(X, y, theta):\n",
    "\n",
    "    y_pred = np.sum(theta * X) #Calculates the predicted value for y_pred\n",
    "    loss = ((y_pred-y)**2)/2    #This is also the cost function. It calculates the \"loss\" (or error) for the current data point\n",
    "\n",
    "    # Your code to return lost and predicted values.\n",
    "    return loss, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ2et9uJ3o4i"
   },
   "source": [
    "# Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "hOrAJ454z8qk"
   },
   "outputs": [],
   "source": [
    "def updateTheta(X, y_pred, y_true, theta, alpha, index):\n",
    "\n",
    "    theta -= alpha *X[index]*(y_pred-y_true[index]) # Adjust theta using the error and the learning rate (alpha).\n",
    "    \n",
    "    # Your code to return theta\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "446lDTRr3vA8"
   },
   "source": [
    "## Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "gGC0RCK00TPF"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, epochs = 10, alpha = 0.001, random_state=0):\n",
    "\n",
    "    num_rows = X.shape[0] # Get the number of rows in the dataset.\n",
    "\n",
    "    num_cols = X.shape[1] # Get the number of columns in the dataset.\n",
    "\n",
    "    # Initialize the theta with small random values, devided by the square root of the number of rows.\n",
    "    theta = np.random.randn(1,num_cols) / np.sqrt(num_rows)\n",
    "   \n",
    "    # Lists to store the total loss for each epoch and the epoch numbers.\n",
    "    train_loss = []\n",
    "    num_epochs = []\n",
    "    \n",
    "    # Generate a list of indices as many as rows in dataset.\n",
    "    train_indices = [i for i in range(X.shape[0])]\n",
    "\n",
    "    # Loop over the specified number of epochs.\n",
    "    for j in range(epochs):\n",
    "        cost=0 # Initialize cost for the current epoch.\n",
    "       \n",
    "        # Set the seed and shuffle the data points.\n",
    "        np.random.seed(random_state)\n",
    "        np.random.shuffle(train_indices)\n",
    "\n",
    "        # Loop over each shuffled index.\n",
    "        for i in train_indices:\n",
    "            \n",
    "            # Compute the prediction and loss for the current data point using the current model parameters.\n",
    "            loss, y_pred = forward(X[i],y[i],theta)\n",
    "            # Accumulate the loss over all data points.\n",
    "            cost+=loss\n",
    "            # Update the model's parameters.\n",
    "            theta = updateTheta(X,y_pred,y,theta,alpha,i)\n",
    "\n",
    "        # Store the total loss for the current epoch.\n",
    "        train_loss.append(cost)\n",
    "        # Store the current epoch number.\n",
    "        num_epochs.append(j)\n",
    "\n",
    "    # Return the final model parameters, the training loss for each epoch, and the epoch numbers.    \n",
    "    return theta, train_loss, num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igWtd1Lo3-ep"
   },
   "source": [
    "## Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "DrEpGXdN0Y2q"
   },
   "outputs": [],
   "source": [
    "def test(X_test, y_test, theta_updated):\n",
    "\n",
    "     # Lists to store predictions and corresponding loss\n",
    "    test_pred = []\n",
    "    test_loss = []\n",
    "\n",
    "    # Generate a list of indices for iterating over the test dataset\n",
    "    test_indices = [i for i in range(X_test.shape[0])]\n",
    "\n",
    "    # Loop over each index in the test dataset.\n",
    "    for i in test_indices:\n",
    "        \n",
    "        # Compute the prediction and loss for the current test data point.\n",
    "        loss, y_test_pred = forward(X_test[i],  y_test[i], theta_updated)\n",
    "        # Store the predicted value for the current test data point.\n",
    "        test_pred.append(y_test_pred)\n",
    "        # Store the loss for the current test data point.\n",
    "        test_loss.append(loss)\n",
    "\n",
    "\n",
    "    # Your code to return predictions and loss\n",
    "    # Return the predictions and loss for the entire test dataset.\n",
    "    return test_pred, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "od4-qZRv4AAf"
   },
   "source": [
    "## Comment each line of the code about what its doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ORSib6yN0dp5"
   },
   "outputs": [],
   "source": [
    "def predict(theta_updated, X_sample):\n",
    "\n",
    "    # Compute the predicted value for the given sample by multiplying with the theta.\n",
    "    prediction = np.sum(theta_updated * X_sample)\n",
    "\n",
    "    # Return the computed prediction.\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrL_oqSeIYO0"
   },
   "source": [
    "# Create a good plot Epochs vs loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "XiryfU2C184a"
   },
   "outputs": [],
   "source": [
    "def plotLoss(loss, epochs):\n",
    "    # Your code to plot epochs vs loss\n",
    "    plt.plot(epochs, loss, c='blue', markersize=5, linestyle='-')\n",
    "    # Your code to print x label in the graph\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    # Your code to print y label in the graph\n",
    "    plt.ylabel(\"Loss\")\n",
    "    # Your code to provide title to the plot.\n",
    "    plt.title(\"Epochs vs Loss\")\n",
    "    # Your code to show the plot.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-MpfkCR4IAb"
   },
   "source": [
    "# Calling the method  split_data to get train and test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "EpxMECnipNSd"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD-K1DXW4yjP"
   },
   "source": [
    "# Call the gradient descent function with the number of epochs and learning rate of your choice. Keep number of epochs greater that 200 and learning rate less than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "L6_XGsxmqKEs"
   },
   "outputs": [],
   "source": [
    "epochs_value = 230 \n",
    "alpha_value = 0.03 \n",
    "theta_updated, train_loss, num_epochs = gradient_descent(X, y, epochs=epochs_value, alpha=alpha_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEaYqXx5PEx"
   },
   "source": [
    "# Test your regression model using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "WTg11ggFqM6A"
   },
   "outputs": [],
   "source": [
    "# Your code to test the model on test data and updated theta values.\n",
    "test_predictions, test_losses = test(X_test, y_test, theta_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYpIBWt05ZdV"
   },
   "source": [
    "# Plot the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Lq4Ld1cTqQCX"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code to plot epochs vs loss. Call the method.\n",
    "plotLoss(train_loss, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eA7JcJ05i3t"
   },
   "source": [
    "Perform the predictions on X_tset. Call predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "bwMj-gm05jqK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6190020606859108, -1.6318343546654908, -1.0298210126169962, 1.3663682251011127, -0.35023870641382, 0.6197721563632771, -0.3711877419734932, 2.1045494756877123, -0.33195843953028825, 0.45577231042645366]\n"
     ]
    }
   ],
   "source": [
    "# Your code to predict the profit i.e. y values\n",
    "predicted_profits = [predict(theta_updated, sample) for sample in X_test]\n",
    "print(predicted_profits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QX9qvbBJ5xI"
   },
   "source": [
    "# **Imortant - Lab Logbook requirement:**\n",
    "\n",
    "# Please document the following in your lab logbook:\n",
    "\n",
    "# 1. Plot the loss function.\n",
    "# 2. Record the output of all the predictions on the test data; i.e., all the predicted y values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFVI2Qkt6tJ4"
   },
   "source": [
    "# **Optional Part:**\n",
    "# The rest of this notebook is Optional. It is recommended for you to complete it. However, if you have not marks would not be deducted.\n",
    "\n",
    "# Fitting the model using sklearn and comparing with our model.\n",
    "\n",
    "# Following piece of code is uncommented. Please comment it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhXzFwONqUCV"
   },
   "outputs": [],
   "source": [
    "# Your code to import train_test_split from sklearn.model_selection\n",
    "# Your code to import LinearRegression from sklearn.linear_model\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4JcuB2Lqby_"
   },
   "outputs": [],
   "source": [
    "dataset_sk = pd.read_csv('50_Startups.csv')\n",
    "X_sk = dataset_sk.iloc[:, :-1].values\n",
    "y_sk = dataset_sk.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3npV2v0qgKD"
   },
   "outputs": [],
   "source": [
    "labelencoder_X_sk = LabelEncoder()\n",
    "X_sk[:,3] = labelencoder_X_sk.fit_transform(X_sk[:,3])\n",
    "\n",
    "onehotencoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_sk_categorical = onehotencoder.fit_transform(X_sk[:,3].reshape(-1,1)).toarray()\n",
    "X_sk = np.concatenate((X_sk,X_sk_categorical),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mwGdW42qn3D"
   },
   "outputs": [],
   "source": [
    "X_sk = X_sk[:, [0,1,2,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1l5re-Qqp_o"
   },
   "outputs": [],
   "source": [
    "X_sk.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx5w-R0lqs2Y"
   },
   "outputs": [],
   "source": [
    "# Your code to perform train test split with 20% data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FtPNcs-9qvPo",
    "outputId": "95195c0f-0486-41f7-aa25-39457f73bd70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_sk = LinearRegression()\n",
    "regressor_sk.fit(X_train_sk, y_train_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDTaghDbqyV4"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = regressor_sk.predict(X_test_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQ6Xu0uOq0uf"
   },
   "outputs": [],
   "source": [
    "X_train_sk.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CE6llxNiq30S"
   },
   "outputs": [],
   "source": [
    "#Making the Prediction using Sklearn Regression\n",
    "print(regressor_sk.predict([[160000,140000,5000000,1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90xW5Wcrq6fc"
   },
   "outputs": [],
   "source": [
    "#Making a Prediction\n",
    "pred = predict(theta_updated,[160000,140000,5000000,1,0,1])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCcFXPhO9yYD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
